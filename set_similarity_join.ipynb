{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "set_similarity_join.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKOOzkchD9i_",
        "outputId": "c7640d78-a623-4323-f358-d59d53ea8453"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/gohdong/2021_autumn/master/BigData/project1/facebook_combined.txt \n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz \n",
        "!tar xf spark-3.1.2-bin-hadoop2.7.tgz\n",
        "!pip install findspark\n",
        "!pip install pyspark\n",
        "!pip install numpy"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-07 15:40:00--  https://raw.githubusercontent.com/gohdong/2021_autumn/master/BigData/project1/facebook_combined.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 854362 (834K) [text/plain]\n",
            "Saving to: ‘facebook_combined.txt.1’\n",
            "\n",
            "facebook_combined.t 100%[===================>] 834.34K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-10-07 15:40:01 (45.5 MB/s) - ‘facebook_combined.txt.1’ saved [854362/854362]\n",
            "\n",
            "--2021-10-07 15:40:03--  https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 224445805 (214M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.1.2-bin-hadoop2.7.tgz.1’\n",
            "\n",
            "spark-3.1.2-bin-had 100%[===================>] 214.05M   169MB/s    in 1.3s    \n",
            "\n",
            "2021-10-07 15:40:04 (169 MB/s) - ‘spark-3.1.2-bin-hadoop2.7.tgz.1’ saved [224445805/224445805]\n",
            "\n",
            "Requirement already satisfied: findspark in /usr/local/lib/python3.7/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_HE1tEUD_Fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "e4703f52-20bd-4354-e91a-428be2c3923d"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "import time\n",
        "findspark.init()\n",
        "from pyspark import SparkContext\n",
        "\n",
        "\n",
        "sc = SparkContext(\"local\",\"ppj\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a16dbc6077be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ppj\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
            "\u001b[0;32m/content/spark-3.1.2-bin-hadoop2.7/python/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    345\u001b[0m                         \u001b[0;34m\" created by %s at %s:%s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 347\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=ppj, master=local) created by __init__ at <ipython-input-2-a16dbc6077be>:11 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhkRZUIjECpB"
      },
      "source": [
        "undirect = sc.textFile('facebook_combined.txt').map(lambda x : x.split(\" \"))\\\n",
        ".flatMap(lambda x: ((int(x[0]),int(x[1])),(int(x[1]),int(x[0])))).groupByKey().mapValues(list)\n",
        "\n",
        "\n",
        "ref = sc.broadcast(dict(undirect.collect()))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14vJEufMEKus"
      },
      "source": [
        "def pp_join(threshold):\n",
        "\n",
        "  def make_pair(item):\n",
        "    arr = item[1]\n",
        "    result = []\n",
        "    for idx,i in enumerate(arr):\n",
        "        for j in arr[idx+1:]:\n",
        "          if not len(ref.value[j]) >= threshold*len(ref.value[i]): continue\n",
        "          result.append(((i,j),1))\n",
        "    return result\n",
        "\n",
        "  def make_invert(item): \n",
        "    key = item[0]\n",
        "    arr= item[1]\n",
        "    result= []\n",
        "    prefix_len = int(len(ref.value[key]) - threshold*len(ref.value[key]) + 1) \n",
        "    for i in arr[:prefix_len]:\n",
        "      result.append((i,key))\n",
        "    return result\n",
        "\n",
        "  def verify(item):\n",
        "    x,y = item[0][0],item[0][1]\n",
        "\n",
        "    Px = int(len(ref.value[x]) - threshold*len(ref.value[x]) + 1)\n",
        "    Py = int(len(ref.value[y]) - threshold*len(ref.value[y]) + 1)\n",
        "\n",
        "    Wx = ref.value[x][Px-1] \n",
        "    Wy = ref.value[y][Py-1]\n",
        "\n",
        "    share = item[1] \n",
        "\n",
        "    a = threshold/(1+threshold)*(len(ref.value[x])+len(ref.value[y]))\n",
        "    value = 0\n",
        "    \n",
        "    if order[Wx] < order[Wy]:                          \n",
        "      value = share + len(set(ref.value[x][Px:])&set(ref.value[y][share:])) \n",
        "\n",
        "    else :                                             \n",
        "      value = share + len(set(ref.value[x][share:])&set(ref.value[y][Py:]))\n",
        "\n",
        "    return value >= a\n",
        "\n",
        "  def is_not_friend(item):\n",
        "    x = item[0][0]\n",
        "    y = item[0][1]\n",
        "    target,arr = x,ref.value[y]\n",
        "    return not (target in arr)\n",
        "\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  A =undirect.map(lambda x: len(x[1])).collect()\n",
        "  B=sorted(range(len(A)),key=lambda x:A[x])\n",
        "  order=sorted(range(len(A)),key=lambda x:B[x])\n",
        "  sorted_undirect = undirect.mapValues(lambda x: sorted(x, key=lambda y : order[y]))\n",
        "\n",
        "  ref = sc.broadcast(dict(sorted_undirect.collect()))\n",
        "\n",
        "  sort_end = time.time() #sort 종료\n",
        "\n",
        "  invert = sorted_undirect.flatMap(make_invert).groupByKey().mapValues(list)\n",
        "  pairs = invert.flatMap(make_pair).reduceByKey(lambda x,y : x+y)\n",
        "  num_pairs = pairs.count()\n",
        "\n",
        "  candidate_end = time.time() # 후보쌍 생성 종료\n",
        "\n",
        "  result = pairs.filter(verify).filter(is_not_friend).flatMap(lambda x: ((x[0][0],x[0][1]),(x[0][1],x[0][0])))\n",
        "  num_result = result.count()\n",
        "\n",
        "  verify_end = time.time() # verify 종료\n",
        "\n",
        "  return num_pairs, num_result,start,sort_end,candidate_end,verify_end"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3NOlvTKI3t8"
      },
      "source": [
        "def all_pairs(threshold):\n",
        "\n",
        "  def make_invert(item):\n",
        "    key = item[0]\n",
        "    arr= item[1]\n",
        "    result= []\n",
        "    prefix_len = int(len(ref.value[key]) - threshold*len(ref.value[key]) + 1) #prefix_filtering \n",
        "    for i in arr[:prefix_len]:\n",
        "      result.append((i,key))\n",
        "    return result\n",
        "\n",
        "  def make_pair(item):\n",
        "    arr = item[1]\n",
        "    result = []\n",
        "    for idx,i in enumerate(arr):\n",
        "        for j in arr[idx+1:]:\n",
        "          if not len(ref.value[j]) >= threshold*len(ref.value[i]): continue #size filtering |x| >= t * |y| \n",
        "          result.append(((i,j),1))\n",
        "    return result\n",
        "\n",
        "  def verify(item):\n",
        "    x = item[0][0]\n",
        "    y = item[0][1]\n",
        "\n",
        "    value = len(list(set(ref.value[x])&set(ref.value[y]))) / len(list(set(ref.value[x])|set(ref.value[y])))\n",
        "    return threshold <= value\n",
        "\n",
        "  def is_not_friend(item):\n",
        "    x = item[0][0]\n",
        "    y = item[0][1]\n",
        "    target,arr = x,ref.value[y]\n",
        "    return not (target in arr)\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  A =undirect.map(lambda x: len(x[1])).collect()\n",
        "  B=sorted(range(len(A)),key=lambda x:A[x])\n",
        "  order=sorted(range(len(A)),key=lambda x:B[x])\n",
        "  sorted_undirect = undirect.mapValues(lambda x: sorted(x, key=lambda y : order[y]))\n",
        "\n",
        "  ref = sc.broadcast(dict(sorted_undirect.collect()))\n",
        "\n",
        "  sort_end = time.time() #sort 종료\n",
        "\n",
        "  invert = sorted_undirect.flatMap(make_invert).groupByKey().mapValues(list)\n",
        "  pairs = invert.flatMap(make_pair).reduceByKey(lambda x,y : x+y)\n",
        "  num_pairs = pairs.count()\n",
        "\n",
        "  candidate_end = time.time() # 후보쌍 생성 종료\n",
        "\n",
        "  result = pairs.filter(verify).filter(is_not_friend).flatMap(lambda x: ((x[0][0],x[0][1]),(x[0][1],x[0][0])))\n",
        "  num_result = result.count()\n",
        "\n",
        "  verify_end = time.time() # verify 종료\n",
        "\n",
        "  return num_pairs, num_result,start,sort_end,candidate_end,verify_end"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kyoKRrXLxKl"
      },
      "source": [
        "def brute_force(threshold):\n",
        "\n",
        "    def make_invert(item):\n",
        "      key= item[0]\n",
        "      arr = item[1]\n",
        "      result = []\n",
        "      for i in arr:\n",
        "          result.append((i,key))\n",
        "      return result\n",
        "\n",
        "    def make_pairs(item):\n",
        "      result = []\n",
        "      arr = item[1]\n",
        "      for idx,i in enumerate(arr):\n",
        "          for j in arr[idx+1:]:\n",
        "              result.append(((i,j),1))\n",
        "      return result\n",
        "      \n",
        "    def verify(item):\n",
        "      x = item[0][0]\n",
        "      y = item[0][1]\n",
        "      overlap = item[1]\n",
        "      a = threshold/(1+threshold)*(len(ref.value[x])+len(ref.value[y]))\n",
        "      return overlap >= a\n",
        "    \n",
        "    def is_not_friend(item):\n",
        "      x = item[0][0]\n",
        "      y = item[0][1]\n",
        "      target,arr = x,ref.value[y]\n",
        "      return not (target in arr)\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    ref = sc.broadcast(dict(undirect.collect()))\n",
        "    \n",
        "    sort_end = time.time() #sort 종료\n",
        "\n",
        "    invert = undirect.flatMap(make_invert).groupByKey().mapValues(list)\n",
        "    pairs = invert.flatMap(make_pairs).reduceByKey(lambda x,y : x+y)\n",
        "    num_pairs = pairs.count()\n",
        "\n",
        "    candidate_end = time.time() # 후보쌍 생성 종료\n",
        "\n",
        "    result = pairs.filter(verify).filter(is_not_friend).flatMap(lambda x: ((x[0][0],x[0][1]),(x[0][1],x[0][0])))\n",
        "    num_result = result.count()\n",
        "\n",
        "    verify_end = time.time() # verify 종료\n",
        "    return num_pairs, num_result,start,sort_end,candidate_end,verify_end"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPg_-H8gOZRC"
      },
      "source": [
        "import numpy\n",
        "\n",
        "t = numpy.arange(0.1, 1, 0.1)\n",
        "brute = []\n",
        "all = []\n",
        "pp = []\n",
        "\n",
        "#threshold에 따른 return 값 배열에 담기\n",
        "for threshold in t:\n",
        "  brute_temp = []\n",
        "  all_temp = []\n",
        "  pp_temp = []\n",
        "  for _ in range(10):\n",
        "    brute_temp.append(brute_force(threshold))\n",
        "    all_temp.append(all_pairs(threshold))\n",
        "    pp_temp.append(pp_join(threshold))\n",
        "\n",
        "  brute.append([sum(i)/10 for i in zip(brute_temp)])\n",
        "  all.append([sum(i)/10 for i in zip(all_temp)])\n",
        "  pp.append([sum(i)/10 for i in zip(pp_temp)])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5c7qKnWDiCl"
      },
      "source": [
        "brute_total = list(zip(*brute))\n",
        "all_total = list(zip(*all))\n",
        "pp_total = list(zip(*pp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crIUdZ4hPNT2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "brute_n_pair = brute_total[0]\n",
        "all_n_pair = all_total[0]\n",
        "pp_n_pair = pp_total[0]\n",
        "\n",
        "plt.plot(t,brute_n_pair,'b',label='brute')\n",
        "plt.plot(t,all_n_pair,'y',label='all')\n",
        "plt.plot(t,pp_n_pair,'r',label='pp')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('number of candidate')\n",
        "plt.xlabel(\"threshold\")\n",
        "plt.show()\n",
        "#threshold 에 따른 발생하는 후보쌍의 개수\n",
        "#brute는 필터링을 하지 않아 threshold에 무관하게 일정\n",
        "#all , pp 는 동일하게 length, prefix 필터링을 거쳐 발생하는 후보쌍 수가 서로 동일함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsOr2LIUGJZM"
      },
      "source": [
        "brute_time = [i-j for i,j in zip(brute_total[5],brute_total[2])]\n",
        "all_time = [i-j for i,j in zip(all_total[5],all_total[2])]\n",
        "pp_time = [i-j for i,j in zip(pp_total[5],pp_total[2])]\n",
        "\n",
        "plt.plot(t,brute_time,'b',label='brute')\n",
        "plt.plot(t,all_time,'y',label='all')\n",
        "plt.plot(t,pp_time,'r',label='pp')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('runtime')\n",
        "plt.xlabel(\"threshold\")\n",
        "plt.show()\n",
        "\n",
        "#threshold 에 따른 전체 실행속도"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNrDwpLMQAG7"
      },
      "source": [
        "brute_sort = [i-j for i,j in zip(brute_total[3],brute_total[2])]\n",
        "all_sort = [i-j for i,j in zip(all_total[3],all_total[2])]\n",
        "pp_sort = [i-j for i,j in zip(pp_total[3],pp_total[2])]\n",
        "\n",
        "plt.plot(t,brute_sort,'b',label='brute')\n",
        "plt.plot(t,all_sort,'y',label='all')\n",
        "plt.plot(t,pp_sort,'r',label='pp')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('time for sort')\n",
        "plt.xlabel(\"threshold\")\n",
        "plt.show()\n",
        "\n",
        "#threshold에 따른 sort에 소요되는 시간\n",
        "# sort를 하지 않는 brute보다 all,pp가 더 많은 시간이 소요된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeccWcRDR6-X"
      },
      "source": [
        "brute_cand = [i-j for i,j in zip(brute_total[4],brute_total[3])]\n",
        "all_cand = [i-j for i,j in zip(all_total[4],all_total[3])]\n",
        "pp_cand = [i-j for i,j in zip(pp_total[4],pp_total[3])]\n",
        "\n",
        "plt.plot(t,brute_cand,'b',label='brute')\n",
        "plt.plot(t,all_cand,'y',label='all')\n",
        "plt.plot(t,pp_cand,'r',label='pp')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('time for generating candidate')\n",
        "plt.xlabel(\"threshold\")\n",
        "plt.show()\n",
        "\n",
        "#threshold에 따른 후보쌍을 생성하는데 소요되는 시간\n",
        "#brute는 필터링을 거치지 않아 threshold와 무관하게 거의 일정하다.\n",
        "#pp,all은 필터링을 거쳐 threshold에 따라 후보쌍의 개수와 생성 시간이 감소된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPLFIjvxSt0A"
      },
      "source": [
        "brute_verify = [i-j for i,j in zip(brute_total[5],brute_total[4])]\n",
        "all_verify  = [i-j for i,j in zip(all_total[5],all_total[4])]\n",
        "pp_verify  = [i-j for i,j in zip(pp_total[5],pp_total[4])]\n",
        "\n",
        "plt.plot(t,brute_verify,'b',label='brute')\n",
        "plt.plot(t,all_verify,'y',label='all')\n",
        "plt.plot(t,pp_verify,'r',label='pp')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('time for verify')\n",
        "plt.xlabel(\"threshold\")\n",
        "plt.show()\n",
        "\n",
        "#threshold에 따른 후보쌍을 판별하는데 소요되는 시간\n",
        "#brute는 필터링을 거치지 않아 후보쌍의 개수가 일정해 판별시간 또한 일정하다. brute: treshold 계산 O(1) / pp,all : 교집합 계산 O(n)\n",
        "#pp, all은 필터링을 거쳐 threshold에 따라 후보쌍의 개수와 판별시간이 감소한다.\n",
        "\n",
        "#pp 는 all보다 추가로 positional imformation 을 이용하므로 all보다 판별 시간이 적게 소요된다."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}